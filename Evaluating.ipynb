{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for inference......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Define whether to use CPU or GPU for benchmarking\n",
    "import os\n",
    "\n",
    "\n",
    "CPU = True\n",
    "\n",
    "if CPU:\n",
    "    print('Using CPU for inference......')\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "else:\n",
    "    print('Using GPU for inference......')\n",
    "\n",
    "\n",
    "%reload_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "if not CPU:\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessity for model loading and compiling\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow_addons as tfa\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def class_map_road(seg):\n",
    "    # map class 0=anything, 1=road\n",
    "    return tf.where(seg == 7, [0, 1.0], [1.0, 0])\n",
    "\n",
    "\n",
    "def cityscapes_prep(output_shape, input_shape=(512,256,3), class_map_func=None, float_range=True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "\n",
    "        img = tf.image.resize(img, input_shape[0:2])\n",
    "        seg = tf.image.resize(seg, output_shape[0:2])\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "def bisenetv2_output_shape(num_classes, scale, input_shape=(512,256,3)):\n",
    "    return ((input_shape[0] // 8) * scale, \n",
    "            (input_shape[1] // 8) * scale, \n",
    "            num_classes)\n",
    "\n",
    "class ArgmaxMeanIOU(metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)\n",
    "\n",
    "\n",
    "decay_steps=10e3\n",
    "momentum=0.9\n",
    "weight_decay=0.0005\n",
    "\n",
    "schedule = optimizers.schedules.PolynomialDecay( initial_learning_rate=5e-2, decay_steps=decay_steps, power=0.9)\n",
    "\n",
    "sgd = tfa.optimizers.SGDW(weight_decay=weight_decay, learning_rate=schedule, momentum=momentum)\n",
    "cce = losses.CategoricalCrossentropy(from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict segmentation and overlay output with an image\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "def img_pred(src,model,image_size):\n",
    "    src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    #cv2_imshow(src)\n",
    "    image = cv2.resize(src,image_size,interpolation=cv2.INTER_CUBIC)\n",
    "    #cv2_imshow(src)\n",
    "    image = image/255\n",
    "    data = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    data = tf.expand_dims(data, axis=0)\n",
    "    s = time.time()\n",
    "    pred = model.predict(data)\n",
    "    e = time.time()\n",
    "    fps = 1/(e-s)\n",
    "    seg = tf.argmax(pred[0], axis=-1)\n",
    "    seg = seg[..., tf.newaxis]\n",
    "    seg = tf.keras.preprocessing.image.array_to_img(seg)\n",
    "    #plt.imshow(seg)\n",
    "    seg = cv2.cvtColor(np.array(seg), cv2.COLOR_BGR2RGB)\n",
    "    seg = cv2.resize(seg,(src.shape[1],src.shape[0]),interpolation=cv2.INTER_CUBIC)\n",
    "    result = cv2.addWeighted(np.array(src), 0.6, seg, 0.5, 0, dtype = cv2.CV_8U)\n",
    "    return src, seg, result, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce Concatenate video of six models\n",
    "import statistics as stat\n",
    "from tqdm import notebook\n",
    "\n",
    "def gen_seg_vid(cap,out,model,subtitle):\n",
    "    length = 1000\n",
    "    progress = notebook.tqdm(total = length)\n",
    "    FPS = [0,0,0]\n",
    "  #while(cap.isOpened()):\n",
    "    for _ in range(length):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            img_out = []\n",
    "            for i in range(len(model)):\n",
    "                total_fps = []\n",
    "                m = model[i]\n",
    "                shape = (256,128)\n",
    "                result = img_pred(frame,m,shape)\n",
    "                img_seg = result[2]\n",
    "                fps = result[3]\n",
    "                total_fps.append(fps)\n",
    "                avg_fps = stat.mean(total_fps)\n",
    "                FPS[i] = avg_fps\n",
    "                x = 'AVG_FPS:'\n",
    "                y = 'FPS: '\n",
    "                img_seg = cv2.resize(img_seg,(512,256),interpolation=cv2.INTER_CUBIC)\n",
    "                text = \"{}{:.3f}\".format(x,avg_fps)\n",
    "                text1 = \"{}{:.3f}\".format(y,fps)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                img_out.append(cv2.cvtColor(img_seg, cv2.COLOR_BGR2RGB))\n",
    "                cv2.putText(img_out[i], text , (350,230), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(img_out[i], text1 , (350,210), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(img_out[i], subtitle[i] , (140,20), font, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            #Verti_512 = np.concatenate((img_out[0], img_out[1]), axis=0)\n",
    "            #Verti_128 = np.concatenate((img_out[2], img_out[3]), axis=0)\n",
    "            #Verti_128_tr = np.concatenate((img_out[4], img_out[5]), axis=0)\n",
    "            img_out[0] = cv2.resize(img_out[0],(1024,512),interpolation=cv2.INTER_CUBIC)\n",
    "            out_img = np.concatenate((img_out[1], img_out[2]), axis=1)\n",
    "            out_img = np.concatenate((out_img, img_out[0]), axis=0)\n",
    "            out_img = cv2.resize(out_img,(1800,1300),interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            out.write(out_img)\n",
    "            progress.update(1)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model with dataset\n",
    "import statistics as stat\n",
    "from tqdm import notebook\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "def run_tflite_model_valid_MIoU(tflite_file, test, size, ALL):\n",
    "    cnt = 0\n",
    "    progress = notebook.tqdm(total = len(test))\n",
    "    for sample in test:\n",
    "        miou = []\n",
    "        total_fps = []\n",
    "        cnt += 1\n",
    "        gt = sample[1]\n",
    "        test_image = sample[0]\n",
    "        \n",
    "        gt = tf.image.resize(gt, size)\n",
    "        gt = tf.argmax(gt, axis=-1)\n",
    "        gt = gt[..., tf.newaxis]\n",
    "  \n",
    "  # Initialize the interpreter\n",
    "        interpreter = tf.lite.Interpreter(model_path=str(tflite_file),num_threads=4)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "        input_details = interpreter.get_input_details()[0]\n",
    "        output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "        test_image = cv2.cvtColor(np.array(test_image), cv2.COLOR_BGR2RGB)\n",
    "        test_image = cv2.resize(test_image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        image = test_image/255\n",
    "        data = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "        data = tf.expand_dims(data, axis=0)\n",
    "        interpreter.set_tensor(input_details[\"index\"], data)\n",
    "  \n",
    "        s = time.time()\n",
    "        interpreter.invoke()\n",
    "        e = time.time()\n",
    "        fps = 1/(e-s)\n",
    "        \n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "        seg = tf.argmax(output, axis=-1)\n",
    "        seg = seg[..., tf.newaxis]\n",
    "        m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "        m.update_state(seg, gt)\n",
    "        miou.append(m.result().numpy())\n",
    "        total_fps.append(fps)\n",
    "        \n",
    "        if not ALL:\n",
    "            x = 'fps: '\n",
    "            text = \"{}{:.3f}\".format(x,fps)\n",
    "            y = \"MIoU: \"\n",
    "            text2 = \"{}{:.3f}\".format(y,m.result().numpy())\n",
    "            z = \"#\"\n",
    "            text3 = \"{}{}\".format(z,cnt)\n",
    "        \n",
    "            seg = tf.keras.preprocessing.image.array_to_img(seg)\n",
    "\n",
    "            seg = cv2.cvtColor(np.array(seg), cv2.COLOR_BGR2RGB)\n",
    "            result = cv2.addWeighted(test_image, 0.6, seg, 0.5, 0, dtype = cv2.CV_8U)\n",
    "            if size == (256,128):\n",
    "                result = cv2.resize(result,(512,256),interpolation=cv2.INTER_CUBIC)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(result, text , (100,250), font, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(result, text2 , (250,250), font, 0.7, (100, 100, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(result, text3 , (10,50), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "            cv2.imshow('result',result)\n",
    "        \n",
    "        progress.update(1)\n",
    "        a = cv2.waitKey(300) if not ALL else cv2.waitKey(0)\n",
    "        if a & 0xFF == ord('q') or cnt == 100 and ALL == False:\n",
    "            break\n",
    "    mean_MIoU = np.round(stat.mean(miou)*100,3)\n",
    "    mean_FPS = np.round(stat.mean(total_fps),3)\n",
    "    cv2.destroyAllWindows()\n",
    "    return mean_MIoU, mean_FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = [(256,512,3),(128, 256, 3)]\n",
    "NUM_CLASSES = 2\n",
    "SCALE = 2\n",
    "OUTPUT_SHAPE = [(256,512,2),(128,256,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscapes = tfds.load('cityscapes/semantic_segmentation',data_dir=\"E:\\EE\\project\\FPGA\\cityscapes\",download=False)\n",
    "\n",
    "valid_ds_1 = cityscapes['validation'].map(cityscapes_prep(OUTPUT_SHAPE[0], INPUT_SHAPE[0], class_map_road))\n",
    "valid_ds_2 = cityscapes['validation'].map(cityscapes_prep(OUTPUT_SHAPE[1], INPUT_SHAPE[1], class_map_road))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "valid_ds_1 = valid_ds_1.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "valid_ds_2 = valid_ds_2.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading is Successful : )\n"
     ]
    }
   ],
   "source": [
    "# load in all tensorflow models for evaluating\n",
    "\n",
    "m1 = tf.keras.models.load_model('E:/EE/project/FPGA/benchmark_model/stripped_pruned_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m1.compile(sgd, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "m1_pc = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_2_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m1_pc.compile(opt, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "m2 = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/original_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m2.compile(sgd, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "m2_pc = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_3_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m2_pc.compile(opt, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "m3 = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/bisenet_small.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m3.compile(sgd, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "m3_pc = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m3_pc.compile(opt, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)] )\n",
    "\n",
    "model = [m1, m1_pc, m2, m2_pc, m3, m3_pc]\n",
    "\n",
    "if model is not None:\n",
    "    print('Loading is Successful : )')\n",
    "else:\n",
    "    print('Loading has Failed : (')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps = 11.520566043436583\n"
     ]
    }
   ],
   "source": [
    "# Test Image\n",
    "src = cv2.imread('E:/EE/project/FPGA/test_01.png')\n",
    "start = time.time()\n",
    "result = img_pred(src,model[1],(256,128))[2]\n",
    "end = time.time()\n",
    "result = cv2.resize(result,(1024,512))\n",
    "fps = 1/(end-start)\n",
    "print('fps =',fps)\n",
    "cv2.imshow(\"result\",result)\n",
    "cv2.waitKey (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate bise small 2 on valid data\n",
      "32/32 [==============================] - 48s 1s/step - loss: 0.1566 - accuracy: 0.9377 - argmax_mean_iou_6: 0.8708\n",
      "Evaluate P small 2 20% on valid data\n",
      "32/32 [==============================] - 39s 1s/step - loss: 0.1228 - accuracy: 0.9517 - argmax_mean_iou_7: 0.8964\n",
      "Evaluate model(256x128) on valid data\n",
      "32/32 [==============================] - 31s 809ms/step - loss: 0.2001 - accuracy: 0.9202 - argmax_mean_iou_8: 0.8328\n",
      "Evaluate pruned bise small 70% on valid data\n",
      "32/32 [==============================] - 31s 921ms/step - loss: 0.1406 - accuracy: 0.9490 - argmax_mean_iou_9: 0.8915\n",
      "Evaluate bise small on valid data\n",
      "32/32 [==============================] - 33s 930ms/step - loss: 0.1239 - accuracy: 0.9491 - argmax_mean_iou_10: 0.8907\n",
      "Evaluate P bise sbmall on valid data\n",
      "32/32 [==============================] - 30s 893ms/step - loss: 0.1215 - accuracy: 0.9504 - argmax_mean_iou_11: 0.8937\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate bise small 2 on valid data\")\n",
    "results1 = model[0].evaluate(valid_ds_2)\n",
    "print(\"Evaluate P small 2 20% on valid data\")\n",
    "results2 = model[1].evaluate(valid_ds_2)\n",
    "print(\"Evaluate model(256x128) on valid data\")\n",
    "results1 = model[2].evaluate(valid_ds_2)\n",
    "print(\"Evaluate pruned bise small 70% on valid data\")\n",
    "results2 = model[3].evaluate(valid_ds_2)\n",
    "print(\"Evaluate bise small on valid data\")\n",
    "results1 = model[4].evaluate(valid_ds_2)\n",
    "print(\"Evaluate P bise sbmall on valid data\")\n",
    "results2 = model[5].evaluate(valid_ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading is Successful : )\n"
     ]
    }
   ],
   "source": [
    "# load in all tensorflow models for evaluating\n",
    "\n",
    "m1 = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_2_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m2 = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_3_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "m3 = tf.keras.models.load_model('E:/EE/project/FPGA/128x256/stripped_pruned_small_model.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "\n",
    "model = [m1, m2, m3]\n",
    "\n",
    "if model is not None:\n",
    "    print('Loading is Successful : )')\n",
    "else:\n",
    "    print('Loading has Failed : (')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('E:\\EE\\project\\FPGA\\data_rural.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('E:/EE/project/FPGA/Original_rural_CPU.mp4',fourcc,10,(1800,1300))\n",
    "\n",
    "subtitle = ['PC Model(512x256)', 'PC Model(128x256)', 'PC Transfer(128x256)']\n",
    "\n",
    "FPS = gen_seg_vid(cap,out,model,subtitle)\n",
    "\n",
    "print('FPS of Pruned clustered model(512x256): ', np.round(FPS[0],3))\n",
    "print('FPS of Pruned clustered model(256x128): ', np.round(FPS[1],3))\n",
    "print('FPS of Pruned clustered transfer model(256x128): ', np.round(FPS[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c73ae404c947a3a3d49077d3dc755a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS of BM 2 20% Model:  8.874\n",
      "FPS of BM2 70% model:  8.835\n",
      "FPS of BM 20% model):  9.035\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('E:\\EE\\project\\FPGA\\Driving_data.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('E:/EE/project/FPGA/Original_CPU.mp4',fourcc,10,(1800,1300))\n",
    "\n",
    "subtitle = ['BM 2 20% Model(128x256)', 'BM2 70% (128x256)', 'BM 20% model(128x256)']\n",
    "\n",
    "FPS = gen_seg_vid(cap,out,model,subtitle)\n",
    "\n",
    "print('FPS of BM 2 20% Model: ', np.round(FPS[0],3))\n",
    "print('FPS of BM2 70% model: ', np.round(FPS[1],3))\n",
    "print('FPS of BM 20% model): ', np.round(FPS[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('E:\\EE\\project\\FPGA\\Drive_Taiwan.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('E:/EE/project/FPGA/Original_Taiwan_CPU.mp4',fourcc,10,(1800,1300))\n",
    "\n",
    "subtitle = ['PC Model(512x256)', 'PC Model(128x256)', 'PC Transfer(128x256)']\n",
    "\n",
    "FPS = gen_seg_vid(cap,out,model,subtitle)\n",
    "\n",
    "print('FPS of Pruned clustered model(512x256): ', np.round(FPS[0],3))\n",
    "print('FPS of Pruned clustered model(256x128): ', np.round(FPS[1],3))\n",
    "print('FPS of Pruned clustered transfer model(256x128): ', np.round(FPS[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def get_size(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "print('Size of 512x256 model: ' , np.round(get_size('E:/EE/project/FPGA/512x256/model8.tf')/1e6,3), 'MB')\n",
    "print('Size of 512x256 PC model: ' , np.round(get_size('E:/EE/project/FPGA/512x256/stripped_sparsity_clustered_model.tf')/1e6,3), 'MB')\n",
    "print('Size of 256x128 model: ' , np.round(get_size('E:/EE/project/FPGA/128x256/original_model.tf')/1e6,3), 'MB')\n",
    "print('Size of 256x128 PC model: ' , np.round(get_size('E:/EE/project/FPGA/128x256/stripped_sparsity_clustered_model.tf')/1e6,3), 'MB')\n",
    "print('Size of 256x128 transfer model: ' , np.round(get_size('E:/EE/project/FPGA/128x256/transfer_model.tf')/1e6,3), 'MB')\n",
    "print('Size of 256x128 transfer PC model: ' , np.round(get_size('E:/EE/project/FPGA/128x256/stripped_sparsity_clustered_transfer_model.tf')/1e6,3), 'MB')\n",
    "\n",
    "print('\\nUnquant model has size ', np.round(os.stat('E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_notquant.tflite').st_size/1e6,3), ' MB')\n",
    "print('Quant model with sparsity INT8/float32 has size ', np.round(os.stat('E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_EXPiof32.tflite').st_size/1e6,3), ' MB')\n",
    "print('Quant model with full INT8 has size ', np.round(os.stat('E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_fullyINT8.tflite').st_size/1e6,3), ' MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4bba4629d0469b9991f8e6b2559bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU of bsmall 70% PC model:  72.239 %\n",
      "Mean FPS of bisenet 80% model:  0.417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d39d0e5d1394da6ab5d9706e6d246c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU of bsmall 20% model:  72.82 %\n",
      "Mean FPS of bsmall 20% model:  0.421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e5e4743a8a47ff9b773a66ec300513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIoU of bsmall 70%  model:  72.698 %\n",
      "Mean FPS of bsmall 70%  model:  0.406\n"
     ]
    }
   ],
   "source": [
    "cityscapes = tfds.load('cityscapes/semantic_segmentation',data_dir=\"E:\\EE\\project\\FPGA\\cityscapes\",download=False)\n",
    "test_ds = cityscapes['validation'].map(cityscapes_prep(OUTPUT_SHAPE[1], INPUT_SHAPE[1], class_map_road, float_range=False))\n",
    "test = test_ds.shuffle(len(test_ds)).take(100)\n",
    "\n",
    "path1 = \"E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_f32_small_2_pc.tflite\"\n",
    "path2 = \"E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_f32_small_2.tflite\"\n",
    "path3 = \"E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_f32_small_3.tflite\"\n",
    "#path3 = \"E:/EE/project/FPGA/128x256/cityscapes_tflite_models/cityscapes_notquant.tflite\"\n",
    "\n",
    "Test_on_all = True\n",
    "\n",
    "\n",
    "R = run_tflite_model_valid_MIoU(path1,test_ds,(256,128),Test_on_all)\n",
    "print('MIoU of bsmall 70% PC model: ', R[0], '%')\n",
    "print('Mean FPS of bisenet 80% model: ', R[1])\n",
    "\n",
    "R = run_tflite_model_valid_MIoU(path2,test_ds,(256,128),Test_on_all)\n",
    "print('MIoU of bsmall 20% model: ', R[0], '%')\n",
    "print('Mean FPS of bsmall 20% model: ', R[1])\n",
    "\n",
    "R = run_tflite_model_valid_MIoU(path3,test_ds,(256,128),Test_on_all)\n",
    "print('MIoU of bsmall 70%  model: ', R[0], '%')\n",
    "print('Mean FPS of bsmall 70%  model: ', R[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
