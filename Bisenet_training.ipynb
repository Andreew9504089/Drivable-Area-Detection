{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd88130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\andre\\anaconda3\\envs\\Py3.6\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-408d5e5d6f31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.data import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826fee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3000)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452678fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "# default input shape\n",
    "INPUT_SHAPE = (512, 1024, 3)\n",
    "\n",
    "\n",
    "def ge_layer(x_in, c, e=6, stride=1):\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    if stride == 2:\n",
    "        x = layers.DepthwiseConv2D(depth_multiplier=e, kernel_size=(3,3), strides=2, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        y = layers.DepthwiseConv2D(depth_multiplier=e, kernel_size=(3,3), strides=2, padding='same')(x_in)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.Conv2D(filters=c, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(y)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "    else:\n",
    "        y = x_in\n",
    "        \n",
    "    x = layers.DepthwiseConv2D(depth_multiplier=e, kernel_size=(3,3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Add()([x, y])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stem(x_in, c):\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), strides=2, padding='same')(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x_split = layers.Activation('relu')(x)\n",
    "    \n",
    "    #x = layers.MaxPool2D(pool_size=(1, 1), padding='same')(x_split)\n",
    "    x = layers.Conv2D(filters=c // 2, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x_split)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    y = layers.MaxPooling2D()(x_split)\n",
    "    \n",
    "    x = layers.Concatenate()([x, y])\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def detail_conv2d(x_in, c, stride=1):\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), strides=stride, padding='same')(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def context_embedding(x_in, c):\n",
    "    x = layers.GlobalAveragePooling2D()(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Reshape((1,1,c))(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=c, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    # broadcasting no needed\n",
    "    print(x_in)\n",
    "    print(x)\n",
    "    x = layers.Add()([x, x_in])\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bilateral_guided_aggregation(detail, semantic, c):\n",
    "    # detail branch\n",
    "    detail_a = layers.DepthwiseConv2D(kernel_size=(3,3), padding='same')(detail)\n",
    "    detail_a = layers.BatchNormalization()(detail_a)\n",
    "    \n",
    "    detail_a = layers.Conv2D(filters=c, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(detail_a)\n",
    "    \n",
    "    #detail_a = layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same')(detail_a)\n",
    "    \n",
    "    detail_b = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), strides=2, padding='same')(detail)\n",
    "    detail_b = layers.BatchNormalization()(detail_b)\n",
    "    \n",
    "    detail_b = layers.AveragePooling2D((3,3), strides=2, padding='same')(detail_b)\n",
    "    \n",
    "    # semantic branch\n",
    "    semantic_a = layers.DepthwiseConv2D(kernel_size=(3,3), padding='same')(semantic)\n",
    "    semantic_a = layers.BatchNormalization()(semantic_a)\n",
    "    \n",
    "    #semantic_a = layers.MaxPool2D(pool_size=(1, 1), padding='same')(semantic_a)\n",
    "    semantic_a = layers.Conv2D(filters=c, kernel_size=(1,1),kernel_regularizer=regularizers.l2(5e-4), padding='same')(semantic_a)\n",
    "    semantic_a = layers.Activation('sigmoid')(semantic_a)\n",
    "    \n",
    "    semantic_b = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(semantic)\n",
    "    semantic_b = layers.BatchNormalization()(semantic_b)\n",
    "    \n",
    "    #semantic_b = layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same')(semantic_b)\n",
    "    \n",
    "    semantic_b = layers.UpSampling2D((4,4), interpolation='bilinear')(semantic_b)\n",
    "    semantic_b = layers.Activation('sigmoid')(semantic_b)\n",
    "    \n",
    "    # combining\n",
    "    detail = layers.Multiply()([detail_a, semantic_b])\n",
    "    semantic = layers.Multiply()([semantic_a, detail_b])\n",
    "    \n",
    "    # this layer is not mentioned in the paper !?\n",
    "    #semantic = layers.UpSampling2D((4,4))(semantic)\n",
    "    semantic = layers.UpSampling2D((4,4), interpolation='bilinear')(semantic)\n",
    "    \n",
    "    x = layers.Add()([detail, semantic])\n",
    "    x = layers.Conv2D(filters=c, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def seg_head(x_in, c_t, s, n):\n",
    "    x = layers.Conv2D(filters=c_t, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=n, kernel_size=(3,3),kernel_regularizer=regularizers.l2(5e-4), padding='same')(x)\n",
    "    x = layers.UpSampling2D((s,s), interpolation='bilinear')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "class ArgmaxMeanIOU(metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)\n",
    "\n",
    "\n",
    "def bisenetv2(num_classes=2, out_scale=8, input_shape=INPUT_SHAPE, l=4, seghead_expand_ratio=2):\n",
    "    x_in = layers.Input(input_shape)\n",
    "\n",
    "    # semantic branch\n",
    "    # S1 + S2\n",
    "    x = stem(x_in, 16 // 1)\n",
    "    \n",
    "    # S3\n",
    "    x = ge_layer(x, 32 // 1, stride=2)\n",
    "    x = ge_layer(x, 32 // 1, stride=1)\n",
    "\n",
    "    # S4\n",
    "    #x = ge_layer(x, 64, stride=2)\n",
    "    #x = ge_layer(x, 64, stride=1)\n",
    "\n",
    "    # S5\n",
    "    #x = ge_layer(x, 128, stride=2)\n",
    "\n",
    "    #x = ge_layer(x, 128, stride=1)\n",
    "    #x = ge_layer(x, 128, stride=1)\n",
    "    #x = ge_layer(x, 128, stride=1)\n",
    "\n",
    "    #x = context_embedding(x, 128)\n",
    "    x = context_embedding(x, 32)\n",
    "\n",
    "    # detail branch\n",
    "    # S1\n",
    "    y = detail_conv2d(x_in, 64, stride=2)\n",
    "    y = detail_conv2d(y, 64, stride=1)\n",
    "\n",
    "    # S2\n",
    "    #y = detail_conv2d(y, 64, stride=2)\n",
    "    #y = detail_conv2d(y, 64, stride=1)\n",
    "    #y = detail_conv2d(y, 64, stride=1)\n",
    "\n",
    "    # S3\n",
    "    #y = detail_conv2d(y, 128, stride=2)\n",
    "    #y = detail_conv2d(y, 128, stride=1)\n",
    "    #y = detail_conv2d(y, 128, stride=1)\n",
    "\n",
    "    #x = bilateral_guided_aggregation(y, x, 128)\n",
    "    x = bilateral_guided_aggregation(y, x, 64)\n",
    "\n",
    "    x = seg_head(x, num_classes * seghead_expand_ratio, out_scale, num_classes)\n",
    "    \n",
    "    model = models.Model(inputs=[x_in], outputs=[x])\n",
    "    \n",
    "    # set weight initializers\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel_initializer = tf.keras.initializers.HeNormal()\n",
    "        if hasattr(layer, 'depthwise_initializer'):\n",
    "            layer.depthwise_initializer = tf.keras.initializers.HeNormal()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def bisenetv2_compiled(num_classes, warmup_steps, decay_steps=5e4, momentum=0.9, weight_decay=0.0005, warmup=True, moving_avg=True, opt_type=1, lr_type=0, **kwargs):\n",
    "    model = bisenetv2(num_classes, **kwargs)\n",
    "\n",
    "    poly = optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=5e-2,\n",
    "        decay_steps=decay_steps,\n",
    "        power=0.9\n",
    "    )\n",
    "    \n",
    "    cosine = optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate = 5e-2, decay_steps=decay_steps, alpha=0.0)\n",
    "    \n",
    "    poly_cycle = optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=5e-2,\n",
    "        decay_steps=decay_steps,\n",
    "        power=0.9,\n",
    "        cycle = True)\n",
    "    \n",
    "    lr = [poly, cosine, poly_cycle]\n",
    "    schedule = lr[lr_type]\n",
    "    \n",
    "    if warmup:\n",
    "        lr_schedule = WarmUp(\n",
    "        initial_learning_rate=5e-2,\n",
    "        decay_schedule_fn=schedule,\n",
    "        warmup_steps=warmup_steps)\n",
    "    else:\n",
    "        lr_schedule = schedule\n",
    "    \n",
    "    sgdw = tfa.optimizers.SGDW(\n",
    "            weight_decay=weight_decay,\n",
    "            learning_rate=lr_schedule,\n",
    "            momentum=momentum\n",
    "        )\n",
    "    sgd = optimizers.SGD(\n",
    "            learning_rate=lr_schedule,\n",
    "            momentum=momentum,\n",
    "        )\n",
    "    \n",
    "    adamw = tfa.optimizers.AdamW(learning_rate=lr_schedule , weight_decay=weight_decay)\n",
    "    \n",
    "    optimizer = [sgdw, sgd, adamw]\n",
    "    \n",
    "    if moving_avg:\n",
    "        opt = tfa.optimizers.MovingAverage(optimizer[opt_type], start_step=warmup_steps, dynamic_decay=True)\n",
    "    opt = optimizer[opt_type]\n",
    "    cce = losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(opt, loss=cce,\n",
    "                  metrics=['accuracy', ArgmaxMeanIOU(num_classes)]) \n",
    "    \n",
    "    return model\n",
    "\n",
    "class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(\n",
    "    self,\n",
    "    initial_learning_rate: float,\n",
    "    decay_schedule_fn: Callable,\n",
    "    warmup_steps: int,\n",
    "    power: float = 1.0,\n",
    "    name: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.power = power\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"WarmUp\") as name:\n",
    "            # Implements polynomial warmup. i.e., if global_step < warmup_steps, the\n",
    "            # learning rate will be `global_step/num_warmup_steps * init_lr`.\n",
    "            global_step_float = tf.cast(step, tf.float32)\n",
    "            warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)\n",
    "            warmup_percent_done = global_step_float / warmup_steps_float\n",
    "            warmup_learning_rate = (self.initial_learning_rate) * tf.math.pow(warmup_percent_done, self.power)\n",
    "            return tf.cond(\n",
    "                global_step_float < warmup_steps_float,\n",
    "                lambda: warmup_learning_rate,\n",
    "                lambda: self.decay_schedule_fn(step - self.warmup_steps),\n",
    "                name=name,\n",
    "            )\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_schedule_fn\": self.decay_schedule_fn,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"power\": self.power,\n",
    "            \"name\": self.name,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df38df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "seed = 123\n",
    "\n",
    "Crop_img = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomCrop(128, 256, seed=seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Crop_seg= tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomCrop(128, 256, seed=seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "seed = 456\n",
    "\n",
    "Zoom_img = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomZoom((-0.75,0.25), fill_mode='constant', seed = seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Zoom_seg = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomZoom((-0.75,0.25), fill_mode='constant', seed = seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "seed= 789\n",
    "\n",
    "Flip_img = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Flip_seg = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "def class_map_road(seg):\n",
    "    # map class 0=anything, 1=road\n",
    "    return tf.where(seg == 7, [0, 1.0], [1.0, 0])\n",
    "\n",
    "\n",
    "def cityscapes_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, input_shape[0:2], method='bilinear')\n",
    "        seg = tf.image.resize(seg, output_shape[0:2], method='nearest')\n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Flip_img(img)\n",
    "        seg = Flip_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "def Zoom_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, input_shape[0:2], method='bilinear')\n",
    "        seg = tf.image.resize(seg, output_shape[0:2], method='nearest')\n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Zoom_img(img)\n",
    "        seg = Zoom_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "        print(seg)\n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "def Crop_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True, Training = True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, (200,400), method='bilinear')\n",
    "        seg = tf.image.resize(seg, (200,400), method='nearest')\n",
    "                    \n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Crop_img(img)\n",
    "        seg = Crop_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "def augment(img, seg, seed):\n",
    "        #seed = tf.random.uniform((2,))\n",
    "        print(seg)\n",
    "        img = tf.image.stateless_random_brightness(img, 0.2, seed=seed)\n",
    "        img = tf.image.stateless_random_contrast(img, 0.8, 1.2, seed=seed)\n",
    "        img = tf.clip_by_value(img, 0.0, 1.0) # clip values outside 0..1\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "def randomize(img, seg):\n",
    "        seed = rng.make_seeds(2)[0]\n",
    "        img, seg = augment(img, seg, seed)\n",
    "        return img, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38d6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def segmentation_to_image(pred):\n",
    "    img = tf.argmax(pred, axis=-1)\n",
    "    img = img[..., tf.newaxis]\n",
    "    return tf.keras.preprocessing.image.array_to_img(img)\n",
    "\n",
    "        \n",
    "def predict_tf(model):\n",
    "    def predict_func(sample):\n",
    "        print(sample[0])\n",
    "        pred = model.predict(tf.expand_dims(sample[0], axis=0))\n",
    "        return sample[0], pred[0]\n",
    "    \n",
    "    return predict_func\n",
    "\n",
    "\n",
    "def display_dataset(ds, pred_func):\n",
    "    for sample in ds:\n",
    "        imgs = pred_func(sample)\n",
    "        fig, axes = plt.subplots(1, len(imgs))\n",
    "        \n",
    "        for ax, img in zip(axes, imgs):\n",
    "            if img.shape[-1] != 3:\n",
    "                img = segmentation_to_image(img)\n",
    "                \n",
    "            ax.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b51c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 128, 16)  448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 128, 16)  64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 128, 16)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 128, 8)   136         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 128, 8)   32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 128, 8)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 64, 16)   1168        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 64, 16)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 64, 32)   0           activation_2[0][0]               \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 64, 16)   4624        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 64, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 64, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 64, 32)   4640        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 64, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 64, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseConv (None, 16, 32, 192)  1920        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 32, 192)  768         depthwise_conv2d[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 16, 32, 1152) 11520       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 16, 32, 96)   960         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 32, 1152) 4608        depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 32, 96)   384         depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 32, 32)   36896       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 32, 32)   3104        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 32, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 32, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 32, 32)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 32, 32)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 32, 32)   9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 32, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 32, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 16, 32, 192)  1920        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 32, 192)  768         depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 32, 32)   6176        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 32, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 32, 32)   0           batch_normalization_12[0][0]     \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 32, 32)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 32)           0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32)           128         global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 128, 64)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 1, 32)     1056        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 128, 64)  256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, 1, 32)     128         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 128, 64)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 1, 32)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 128, 64)  36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 32, 32)   0           activation_8[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 128, 64)  256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 32, 32)   9248        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 128, 64)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 16, 32, 32)   320         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 32, 64)   18496       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 32, 32)   128         depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 64, 64)   36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 64, 128, 64)  640         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 32, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 32, 64)   2112        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 64, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 128, 64)  256         depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 128, 64)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 32, 64)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 32, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 128, 64)  4160        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 128, 64)  0           up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16, 32, 64)   0           activation_11[0][0]              \n",
      "                                                                 average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 64, 128, 64)  0           conv2d_13[0][0]                  \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 128, 64)  0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 128, 64)  0           multiply[0][0]                   \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 128, 64)  36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 128, 64)  256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 128, 4)   2308        batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 128, 4)   16          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 128, 4)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 128, 2)   74          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 256, 2)  0           conv2d_19[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 243,078\n",
      "Trainable params: 238,414\n",
      "Non-trainable params: 4,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (128, 256, 3)\n",
    "OUTPUT_SHAPE = (128, 256, 2)\n",
    "NUM_CLASSES = 2\n",
    "SCALE = 2\n",
    "m = bisenetv2_compiled(num_classes=NUM_CLASSES, out_scale=SCALE, input_shape=INPUT_SHAPE, warmup=True, opt_type=1, lr_type=1, warmup_steps=5*744)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1975e49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SelectV2:0\", shape=(128, 256, 2), dtype=float32)\n",
      "Tensor(\"args_1:0\", shape=(128, 256, 2), dtype=float32)\n",
      "<PrefetchDataset shapes: ((None, 128, 256, 3), (None, 128, 256, 2)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "\n",
    "cityscapes = tfds.load('cityscapes/semantic_segmentation',data_dir=\"E:\\EE\\project\\FPGA\\cityscapes\",download=False,shuffle_files=True)\n",
    "train_ds = cityscapes['train'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "valid_ds = cityscapes['validation'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "test_ds = cityscapes['test'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "crop_train = cityscapes['train'].map(Crop_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "zoom_train = cityscapes['train'].map(Zoom_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "tmp_ds = train_ds.concatenate(crop_train).concatenate(zoom_train)\n",
    "train_rand = tmp_ds.map(randomize)\n",
    "fit_ds = tmp_ds.concatenate(train_rand)\n",
    "\n",
    "fit_ds = fit_ds.batch(16).prefetch(AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(4).prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.batch(4).prefetch(AUTOTUNE)\n",
    "print(fit_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4094ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "  \n",
    "USE_AUGMENTATION = True\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "    \n",
    "if USE_AUGMENTATION:\n",
    "\n",
    "    def augment(img, seg, seed):\n",
    "        #seed = tf.random.uniform((2,))\n",
    "        print(seg)\n",
    "        img = tf.image.stateless_random_brightness(img, 0.2, seed=seed)\n",
    "        img = tf.image.stateless_random_contrast(img, 0.8, 1.2, seed=seed)\n",
    "        img = tf.image.stateless_random_saturation(img, 0.0, 1.5, seed=seed)\n",
    "        img = tf.image.stateless_random_hue(img, 0.2, seed=seed)\n",
    "        img = tf.clip_by_value(img, 0.0, 1.0) # clip values outside 0..1\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "    def randomize(img, seg):\n",
    "        seed = rng.make_seeds(2)[0]\n",
    "        img, seg = augment(img, seg, seed)\n",
    "        return img, seg\n",
    "    \n",
    "    train_ds_flipped_lr = train_ds.map(lambda img, seg: (tf.image.flip_left_right(img), tf.image.flip_left_right(seg)))\n",
    "    valid_ds_flipped_lr = valid_ds.map(lambda img, seg: (tf.image.flip_left_right(img), tf.image.flip_left_right(seg)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_ds_randomized = train_ds.map(randomize)\n",
    "    valid_ds_randomized = valid_ds.map(randomize)\n",
    "    \n",
    "    train_ds_randomized_flipped = train_ds_flipped_lr.map(randomize)\n",
    "    valid_ds_randomized_flipped = valid_ds_flipped_lr.map(randomize)\n",
    "    \n",
    "    train_ds = train_ds.concatenate(train_ds_flipped_lr).concatenate(train_ds_randomized).concatenate(train_ds_randomized_flipped)\n",
    "    valid_ds = valid_ds.concatenate(valid_ds_flipped_lr).concatenate(valid_ds_randomized).concatenate(valid_ds_randomized_flipped)\n",
    "\n",
    "    #train_ds = train_ds.concatenate(train_ds_flipped_lr).concatenate(train_ds_randomized).concatenate(crop_ds_flipped).concatenate(train_ds_randomized).concatenate(zoom_ds_flipped)\n",
    "    #train_ds = train_ds.concatenate(aug_ds).concatenate(train_ds_randomized).concatenate(aug_ds_rand)\n",
    "    \n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(4).prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "#display_dataset(valid_ds.unbatch().take(1), lambda s: (s[0], s[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fbaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1116/1116 [==============================] - 1599s 1s/step - loss: 0.6348 - accuracy: 0.8636 - argmax_mean_iou: 0.7473 - val_loss: 2.0063 - val_accuracy: 0.7613 - val_argmax_mean_iou: 0.5295\n",
      "Epoch 2/100\n",
      "1116/1116 [==============================] - 1649s 1s/step - loss: 0.4635 - accuracy: 0.9073 - argmax_mean_iou: 0.8203 - val_loss: 0.8653 - val_accuracy: 0.8316 - val_argmax_mean_iou: 0.6801\n",
      "Epoch 3/100\n",
      "1116/1116 [==============================] - 1667s 1s/step - loss: 0.3326 - accuracy: 0.9192 - argmax_mean_iou: 0.8412 - val_loss: 0.5165 - val_accuracy: 0.8662 - val_argmax_mean_iou: 0.7417\n",
      "Epoch 4/100\n",
      "1116/1116 [==============================] - 1697s 2s/step - loss: 0.2500 - accuracy: 0.9260 - argmax_mean_iou: 0.8533 - val_loss: 0.4590 - val_accuracy: 0.8526 - val_argmax_mean_iou: 0.7132\n",
      "Epoch 5/100\n",
      "1116/1116 [==============================] - 1676s 2s/step - loss: 0.2087 - accuracy: 0.9322 - argmax_mean_iou: 0.8648 - val_loss: 0.5050 - val_accuracy: 0.7653 - val_argmax_mean_iou: 0.5690\n",
      "Epoch 6/100\n",
      "1116/1116 [==============================] - 1699s 2s/step - loss: 0.1918 - accuracy: 0.9356 - argmax_mean_iou: 0.8708 - val_loss: 1.3322 - val_accuracy: 0.6789 - val_argmax_mean_iou: 0.3498\n",
      "Epoch 7/100\n",
      "1116/1116 [==============================] - 1700s 2s/step - loss: 0.1840 - accuracy: 0.9374 - argmax_mean_iou: 0.8741 - val_loss: 0.5800 - val_accuracy: 0.7990 - val_argmax_mean_iou: 0.5852\n",
      "Epoch 8/100\n",
      "1116/1116 [==============================] - 1694s 2s/step - loss: 0.1809 - accuracy: 0.9383 - argmax_mean_iou: 0.8760 - val_loss: 0.4878 - val_accuracy: 0.8065 - val_argmax_mean_iou: 0.6194\n",
      "Epoch 9/100\n",
      "1116/1116 [==============================] - 1676s 2s/step - loss: 0.1752 - accuracy: 0.9404 - argmax_mean_iou: 0.8799 - val_loss: 0.6573 - val_accuracy: 0.7937 - val_argmax_mean_iou: 0.5805\n",
      "Epoch 10/100\n",
      " 663/1116 [================>.............] - ETA: 11:26 - loss: 0.1552 - accuracy: 0.9488 - argmax_mean_iou: 0.8952"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = m.fit(fit_ds,\n",
    "                validation_data=valid_ds,\n",
    "                epochs=EPOCHS,\n",
    "                callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('E:/EE/project/FPGA/benchmark_model/model_benchmark_1.tf')\n",
    "m.save('E:/EE/project/FPGA/benchmark_model/model_benchmark_1.h5',save_format='h5')\n",
    "model_copy = tf.keras.models.clone_model(m)\n",
    "model_copy.set_weights(m.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "def img_pred(src,model,image_size):\n",
    "    src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    #cv2_imshow(src)\n",
    "    image = cv2.resize(src,image_size,interpolation=cv2.INTER_CUBIC)\n",
    "    #cv2_imshow(src)\n",
    "    image = image/255\n",
    "    image =  tf.image.per_image_standardization(image)\n",
    "    data = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    data = tf.expand_dims(data, axis=0)\n",
    "    s = time.time()\n",
    "    pred = model.predict(data)\n",
    "    e = time.time()\n",
    "    fps = 1/(e-s)\n",
    "    seg = tf.argmax(pred[0], axis=-1)\n",
    "    seg = seg[..., tf.newaxis]\n",
    "    seg = tf.keras.preprocessing.image.array_to_img(seg)\n",
    "    #plt.imshow(seg)\n",
    "    seg = cv2.cvtColor(np.array(seg), cv2.COLOR_BGR2RGB)\n",
    "    seg = cv2.resize(seg,(src.shape[1],src.shape[0]),interpolation=cv2.INTER_CUBIC)\n",
    "    result = cv2.addWeighted(np.array(src), 0.6, seg, 0.5, 0, dtype = cv2.CV_8U)\n",
    "    return src, seg, result, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "from tqdm import notebook\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "def gen_seg_vid(cap,out,model,subtitle):\n",
    "    length = 1000\n",
    "    progress = notebook.tqdm(total = length)\n",
    "    AVG_FPS = 0\n",
    "  #while(cap.isOpened()):\n",
    "    for _ in range(length):\n",
    "        ret, frame = cap.read()\n",
    "        cnt = 0\n",
    "        if ret == True:\n",
    "            cnt += 1\n",
    "            total_fps = []\n",
    "            m = model\n",
    "            shape = (256,128)\n",
    "            result = img_pred(frame,m,shape)\n",
    "            img_seg = result[2]\n",
    "            fps = result[3]\n",
    "            total_fps.append(fps)\n",
    "            if cnt == 10:\n",
    "                AVG_FPS = stat.mean(total_fps)\n",
    "                cnt = 0 \n",
    "            x = 'AVG_FPS:'\n",
    "            y = 'FPS: '\n",
    "            img_seg = cv2.resize(img_seg,(512,256),interpolation=cv2.INTER_CUBIC)\n",
    "            text = \"{}{:.3f}\".format(x,AVG_FPS)\n",
    "            text1 = \"{}{:.3f}\".format(y,fps)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            img_out = cv2.cvtColor(img_seg, cv2.COLOR_BGR2RGB)\n",
    "            cv2.putText(img_out, text , (350,230), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img_out, text1 , (350,210), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img_out, subtitle , (140,20), font, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            img_out = cv2.resize(img_out,(1800,1300),interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            out.write(img_out)\n",
    "            progress.update(1)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return AVG_FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('E:/EE/project/FPGA/benchmark_model/model_benchmark1.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "cap = cv2.VideoCapture('E:\\EE\\project\\FPGA\\Driving_data.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('E:/EE/project/FPGA/benchmark_model/City_GPU_1.mp4',fourcc,20,(1800,1300))\n",
    "\n",
    "subtitle = 'Benchmark mIoU(92%)'\n",
    "\n",
    "gen_seg_vid(cap,out,model,subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('E:/EE/project/FPGA/test_02.png')\n",
    "start = time.time()\n",
    "result = img_pred(src,model,(256,128))[2]\n",
    "end = time.time()\n",
    "fps = 1/(end-start)\n",
    "print('fps =',fps)\n",
    "result = cv2.resize(result,(1024,512),interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"result\",result)\n",
    "cv2.waitKey (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48de9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
