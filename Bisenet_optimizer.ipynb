{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302a0371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.data import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a3b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3000)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c0f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "seed = 123\n",
    "\n",
    "Crop_img = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomCrop(128, 256, seed=seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Crop_seg= tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomCrop(128, 256, seed=seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "seed = 456\n",
    "\n",
    "Zoom_img = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomZoom((-0.75,0.25), fill_mode='constant', seed = seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Zoom_seg = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomZoom((-0.75,0.25), fill_mode='constant', seed = seed),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "seed= 789\n",
    "\n",
    "Flip_img = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "Flip_seg = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = seed)\n",
    "])\n",
    "\n",
    "INPUT_SHAPE = (128,256,3)\n",
    "OUTPUT_SHAPE = (128,256,2)\n",
    "\n",
    "def class_map_road(seg):\n",
    "    # map class 0=anything, 1=road\n",
    "    return tf.where(seg == 7, [0, 1.0], [1.0, 0])\n",
    "\n",
    "\n",
    "def cityscapes_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, input_shape[0:2], method='bilinear')\n",
    "        seg = tf.image.resize(seg, output_shape[0:2], method='nearest')\n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Flip_img(img)\n",
    "        seg = Flip_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "def Zoom_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, input_shape[0:2], method='bilinear')\n",
    "        seg = tf.image.resize(seg, output_shape[0:2], method='nearest')\n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Zoom_img(img)\n",
    "        seg = Zoom_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "        print(seg)\n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "def Crop_prep(output_shape, input_shape=INPUT_SHAPE, class_map_func=None, float_range=True, standardize=True, Training = True):\n",
    "    def prep_map(sample):\n",
    "        img = sample['image_left']\n",
    "        seg = sample['segmentation_label']\n",
    "\n",
    "        if float_range:\n",
    "            img /= 255\n",
    "        if standardize:\n",
    "            img = tf.image.per_image_standardization(img)\n",
    "\n",
    "        img = tf.image.resize(img, (200,400), method='bilinear')\n",
    "        seg = tf.image.resize(seg, (200,400), method='nearest')\n",
    "                    \n",
    "        \n",
    "        img = img[None, ...]\n",
    "        seg = seg[None, ...]\n",
    "        img = Crop_img(img)\n",
    "        seg = Crop_seg(seg)\n",
    "        img = tf.squeeze(img)\n",
    "        seg = tf.squeeze(seg,0)\n",
    "        \n",
    "        if callable(class_map_func):\n",
    "            seg = class_map_func(seg)\n",
    "        else:\n",
    "            seg = tf.one_hot(tf.cast(seg, tf.int32), output_shape[-1], axis=2)\n",
    "            seg = tf.cast(seg, tf.float32)\n",
    "            seg = tf.squeeze(seg)\n",
    "            #seg = tf.keras.utils.to_categorical(seg, num_classes=output_shape[-1])\n",
    "        \n",
    "        return img, seg\n",
    "\n",
    "    return prep_map\n",
    "\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "def augment(img, seg, seed):\n",
    "        #seed = tf.random.uniform((2,))\n",
    "        print(seg)\n",
    "        img = tf.image.stateless_random_brightness(img, 0.2, seed=seed)\n",
    "        img = tf.image.stateless_random_contrast(img, 0.8, 1.2, seed=seed)\n",
    "        img = tf.image.stateless_random_saturation(img, 0.0, 1.5, seed=seed)\n",
    "        img = tf.image.stateless_random_hue(img, 0.2, seed=seed)\n",
    "        img = tf.clip_by_value(img, 0.0, 1.0) # clip values outside 0..1\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "def randomize(img, seg):\n",
    "        seed = rng.make_seeds(2)[0]\n",
    "        img, seg = augment(img, seg, seed)\n",
    "        return img, seg\n",
    "\n",
    "class ArgmaxMeanIOU(metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90965d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SelectV2:0\", shape=(128, 256, 2), dtype=float32)\n",
      "<PrefetchDataset shapes: ((None, 128, 256, 3), (None, 128, 256, 2)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "\n",
    "cityscapes = tfds.load('cityscapes/semantic_segmentation',data_dir=\"E:\\EE\\project\\FPGA\\cityscapes\",download=False,shuffle_files=True)\n",
    "train_ds = cityscapes['train'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "valid_ds = cityscapes['validation'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "test_ds = cityscapes['test'].map(cityscapes_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "crop_train = cityscapes['train'].map(Crop_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "zoom_train = cityscapes['train'].map(Zoom_prep(OUTPUT_SHAPE, INPUT_SHAPE, class_map_road))\n",
    "fit_ds = train_ds.concatenate(crop_train).concatenate(zoom_train)\n",
    "\n",
    "fit_ds = fit_ds.batch(16).prefetch(AUTOTUNE)\n",
    "valid_ds = valid_ds.batch(4).prefetch(AUTOTUNE)\n",
    "test_ds = test_ds.batch(4).prefetch(AUTOTUNE)\n",
    "print(fit_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84c3d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d (Pru (None, 64, 128, 16)  882         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 16)  65          prune_low_magnitude_conv2d[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation  (None, 64, 128, 16)  1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (P (None, 64, 128, 8)   266         prune_low_magnitude_activation[0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 8)   33          prune_low_magnitude_conv2d_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 64, 128, 8)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (P (None, 32, 64, 16)   2322        prune_low_magnitude_activation_1[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 32, 64, 16)   65          prune_low_magnitude_conv2d_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 32, 64, 16)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 32, 64, 16)   1           prune_low_magnitude_activation[0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_concatenate (None, 32, 64, 32)   1           prune_low_magnitude_activation_2[\n",
      "                                                                 prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (P (None, 32, 64, 16)   9234        prune_low_magnitude_concatenate[0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 32, 64, 16)   65          prune_low_magnitude_conv2d_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 32, 64, 16)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_4 (P (None, 32, 64, 32)   9250        prune_low_magnitude_activation_3[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 32, 64, 32)   129         prune_low_magnitude_conv2d_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 32, 64, 32)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 16, 32, 192)  1921        prune_low_magnitude_activation_4[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 192)  769         prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 16, 32, 1152) 11521       prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 16, 32, 96)   961         prune_low_magnitude_activation_3[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 1152) 4609        prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 96)   385         prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_6 (P (None, 16, 32, 32)   73762       prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_5 (P (None, 16, 32, 32)   6178        prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 32)   129         prune_low_magnitude_conv2d_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 32)   129         prune_low_magnitude_conv2d_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_add (PruneL (None, 16, 32, 32)   1           prune_low_magnitude_batch_normali\n",
      "                                                                 prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 16, 32, 32)   1           prune_low_magnitude_add[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_7 (P (None, 16, 32, 32)   18466       prune_low_magnitude_activation_5[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 32)   129         prune_low_magnitude_conv2d_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 16, 32, 32)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 16, 32, 192)  1921        prune_low_magnitude_activation_6[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 192)  769         prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_8 (P (None, 16, 32, 32)   12322       prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 32)   129         prune_low_magnitude_conv2d_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_add_1 (Prun (None, 16, 32, 32)   1           prune_low_magnitude_batch_normali\n",
      "                                                                 prune_low_magnitude_activation_5[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 16, 32, 32)   1           prune_low_magnitude_add_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_global_aver (None, 32)           1           prune_low_magnitude_activation_7[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 32)           129         prune_low_magnitude_global_averag\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_reshape (Pr (None, 1, 1, 32)     1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_11 ( (None, 64, 128, 64)  3522        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_9 (P (None, 1, 1, 32)     2082        prune_low_magnitude_reshape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 64)  257         prune_low_magnitude_conv2d_11[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 1, 1, 32)     129         prune_low_magnitude_conv2d_9[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 64, 128, 64)  1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 1, 1, 32)     1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_12 ( (None, 64, 128, 64)  73794       prune_low_magnitude_activation_9[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_add_2 (Prun (None, 16, 32, 32)   1           prune_low_magnitude_activation_8[\n",
      "                                                                 prune_low_magnitude_activation_7[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 64)  257         prune_low_magnitude_conv2d_12[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_10 ( (None, 16, 32, 32)   18466       prune_low_magnitude_add_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 64, 128, 64)  1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 16, 32, 32)   321         prune_low_magnitude_conv2d_10[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_16 ( (None, 16, 32, 64)   36930       prune_low_magnitude_conv2d_10[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 32)   129         prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_14 ( (None, 32, 64, 64)   73794       prune_low_magnitude_activation_10\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_depthwise_c (None, 64, 128, 64)  641         prune_low_magnitude_activation_10\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 16, 32, 64)   257         prune_low_magnitude_conv2d_16[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_15 ( (None, 16, 32, 64)   4162        prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 32, 64, 64)   257         prune_low_magnitude_conv2d_14[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 64)  257         prune_low_magnitude_depthwise_con\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_up_sampling (None, 64, 128, 64)  1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 16, 32, 64)   1           prune_low_magnitude_conv2d_15[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_average_poo (None, 16, 32, 64)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_13 ( (None, 64, 128, 64)  8258        prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 64, 128, 64)  1           prune_low_magnitude_up_sampling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_multiply_1  (None, 16, 32, 64)   1           prune_low_magnitude_activation_11\n",
      "                                                                 prune_low_magnitude_average_pooli\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_multiply (P (None, 64, 128, 64)  1           prune_low_magnitude_conv2d_13[0][\n",
      "                                                                 prune_low_magnitude_activation_12\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_up_sampling (None, 64, 128, 64)  1           prune_low_magnitude_multiply_1[0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_add_3 (Prun (None, 64, 128, 64)  1           prune_low_magnitude_multiply[0][0\n",
      "                                                                 prune_low_magnitude_up_sampling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_17 ( (None, 64, 128, 64)  73794       prune_low_magnitude_add_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 64)  257         prune_low_magnitude_conv2d_17[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_18 ( (None, 64, 128, 4)   4614        prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_batch_norma (None, 64, 128, 4)   17          prune_low_magnitude_conv2d_18[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 64, 128, 4)   1           prune_low_magnitude_batch_normali\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_19 ( (None, 64, 128, 2)   148         prune_low_magnitude_activation_13\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_up_sampling (None, 128, 256, 2)  1           prune_low_magnitude_conv2d_19[0][\n",
      "==================================================================================================\n",
      "Total params: 458,911\n",
      "Trainable params: 238,414\n",
      "Non-trainable params: 220,497\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('E:/EE/project/FPGA/benchmark_model/model_benchmark.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "epochs = 35\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "end_step = np.ceil(len(train_ds)).astype(np.int32)*epochs\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.2,\n",
    "                                    final_sparsity=0.8,\n",
    "                                    begin_step=0,\n",
    "                                    end_step=end_step)}\n",
    "\n",
    "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "sgd = optimizers.SGD(\n",
    "        learning_rate=1e-5,\n",
    "        momentum=0.9,\n",
    "    )\n",
    "\n",
    "opt = tfa.optimizers.MovingAverage(sgd, dynamic_decay=True)\n",
    "cce = losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "pruned_model.compile(opt, loss=cce, metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)]) \n",
    "pruned_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a26e6f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "558/558 [==============================] - 947s 2s/step - loss: 0.0787 - accuracy: 0.9757 - argmax_mean_iou_1: 0.9489 - val_loss: 0.1184 - val_accuracy: 0.9638 - val_argmax_mean_iou_1: 0.9216\n",
      "Epoch 2/35\n",
      "558/558 [==============================] - 937s 2s/step - loss: 0.0780 - accuracy: 0.9760 - argmax_mean_iou_1: 0.9495 - val_loss: 0.1288 - val_accuracy: 0.9618 - val_argmax_mean_iou_1: 0.9174\n",
      "Epoch 3/35\n",
      "558/558 [==============================] - 983s 2s/step - loss: 0.0777 - accuracy: 0.9762 - argmax_mean_iou_1: 0.9498 - val_loss: 0.1262 - val_accuracy: 0.9631 - val_argmax_mean_iou_1: 0.9201\n",
      "Epoch 4/35\n",
      "558/558 [==============================] - 969s 2s/step - loss: 0.0784 - accuracy: 0.9757 - argmax_mean_iou_1: 0.9490 - val_loss: 0.1318 - val_accuracy: 0.9619 - val_argmax_mean_iou_1: 0.9176\n",
      "Epoch 5/35\n",
      "558/558 [==============================] - 996s 2s/step - loss: 0.0783 - accuracy: 0.9758 - argmax_mean_iou_1: 0.9490 - val_loss: 0.1213 - val_accuracy: 0.9635 - val_argmax_mean_iou_1: 0.9210\n",
      "Epoch 6/35\n",
      "558/558 [==============================] - 956s 2s/step - loss: 0.0780 - accuracy: 0.9759 - argmax_mean_iou_1: 0.9493 - val_loss: 0.1272 - val_accuracy: 0.9629 - val_argmax_mean_iou_1: 0.9198\n",
      "Epoch 7/35\n",
      "558/558 [==============================] - 956s 2s/step - loss: 0.0777 - accuracy: 0.9760 - argmax_mean_iou_1: 0.9495 - val_loss: 0.1252 - val_accuracy: 0.9619 - val_argmax_mean_iou_1: 0.9176\n",
      "Epoch 8/35\n",
      "558/558 [==============================] - 955s 2s/step - loss: 0.0769 - accuracy: 0.9764 - argmax_mean_iou_1: 0.9503 - val_loss: 0.1246 - val_accuracy: 0.9610 - val_argmax_mean_iou_1: 0.9158\n",
      "Epoch 9/35\n",
      "558/558 [==============================] - 939s 2s/step - loss: 0.0770 - accuracy: 0.9763 - argmax_mean_iou_1: 0.9501 - val_loss: 0.1269 - val_accuracy: 0.9617 - val_argmax_mean_iou_1: 0.9172\n",
      "Epoch 10/35\n",
      "558/558 [==============================] - 911s 2s/step - loss: 0.0770 - accuracy: 0.9763 - argmax_mean_iou_1: 0.9501 - val_loss: 0.1291 - val_accuracy: 0.9618 - val_argmax_mean_iou_1: 0.9173\n",
      "Epoch 11/35\n",
      "558/558 [==============================] - 941s 2s/step - loss: 0.0774 - accuracy: 0.9761 - argmax_mean_iou_1: 0.9497 - val_loss: 0.1238 - val_accuracy: 0.9624 - val_argmax_mean_iou_1: 0.9185\n",
      "Epoch 12/35\n",
      "558/558 [==============================] - 938s 2s/step - loss: 0.0770 - accuracy: 0.9762 - argmax_mean_iou_1: 0.9499 - val_loss: 0.1230 - val_accuracy: 0.9627 - val_argmax_mean_iou_1: 0.9192\n",
      "Epoch 13/35\n",
      "558/558 [==============================] - 938s 2s/step - loss: 0.0771 - accuracy: 0.9762 - argmax_mean_iou_1: 0.9500 - val_loss: 0.1212 - val_accuracy: 0.9622 - val_argmax_mean_iou_1: 0.9184\n",
      "Epoch 14/35\n",
      "558/558 [==============================] - 953s 2s/step - loss: 0.0772 - accuracy: 0.9762 - argmax_mean_iou_1: 0.9500 - val_loss: 0.1269 - val_accuracy: 0.9622 - val_argmax_mean_iou_1: 0.9183\n",
      "Epoch 15/35\n",
      "558/558 [==============================] - 1021s 2s/step - loss: 0.0779 - accuracy: 0.9761 - argmax_mean_iou_1: 0.9497 - val_loss: 0.1248 - val_accuracy: 0.9620 - val_argmax_mean_iou_1: 0.9179\n",
      "Epoch 16/35\n",
      "558/558 [==============================] - 936s 2s/step - loss: 0.0780 - accuracy: 0.9760 - argmax_mean_iou_1: 0.9496 - val_loss: 0.1244 - val_accuracy: 0.9616 - val_argmax_mean_iou_1: 0.9170\n",
      "Epoch 17/35\n",
      "558/558 [==============================] - 927s 2s/step - loss: 0.0785 - accuracy: 0.9758 - argmax_mean_iou_1: 0.9492 - val_loss: 0.1251 - val_accuracy: 0.9632 - val_argmax_mean_iou_1: 0.9203\n",
      "Epoch 18/35\n",
      "558/558 [==============================] - 945s 2s/step - loss: 0.0772 - accuracy: 0.9763 - argmax_mean_iou_1: 0.9501 - val_loss: 0.1216 - val_accuracy: 0.9618 - val_argmax_mean_iou_1: 0.9172\n",
      "Epoch 19/35\n",
      "558/558 [==============================] - 932s 2s/step - loss: 0.0775 - accuracy: 0.9760 - argmax_mean_iou_1: 0.9496 - val_loss: 0.1235 - val_accuracy: 0.9614 - val_argmax_mean_iou_1: 0.9164\n",
      "Epoch 20/35\n",
      "558/558 [==============================] - 931s 2s/step - loss: 0.0782 - accuracy: 0.9758 - argmax_mean_iou_1: 0.9492 - val_loss: 0.1230 - val_accuracy: 0.9621 - val_argmax_mean_iou_1: 0.9180\n",
      "Epoch 21/35\n",
      "558/558 [==============================] - 945s 2s/step - loss: 0.0780 - accuracy: 0.9760 - argmax_mean_iou_1: 0.9495 - val_loss: 0.1212 - val_accuracy: 0.9622 - val_argmax_mean_iou_1: 0.9181\n",
      "Epoch 22/35\n",
      "558/558 [==============================] - 1064s 2s/step - loss: 0.0782 - accuracy: 0.9759 - argmax_mean_iou_1: 0.9493 - val_loss: 0.1239 - val_accuracy: 0.9619 - val_argmax_mean_iou_1: 0.9175\n",
      "Epoch 23/35\n",
      "558/558 [==============================] - 1019s 2s/step - loss: 0.0784 - accuracy: 0.9758 - argmax_mean_iou_1: 0.9492 - val_loss: 0.1258 - val_accuracy: 0.9610 - val_argmax_mean_iou_1: 0.9158\n",
      "Epoch 24/35\n",
      "558/558 [==============================] - 968s 2s/step - loss: 0.0788 - accuracy: 0.9756 - argmax_mean_iou_1: 0.9488 - val_loss: 0.1204 - val_accuracy: 0.9623 - val_argmax_mean_iou_1: 0.9185\n",
      "Epoch 25/35\n",
      "558/558 [==============================] - 953s 2s/step - loss: 0.0786 - accuracy: 0.9758 - argmax_mean_iou_1: 0.9492 - val_loss: 0.1233 - val_accuracy: 0.9625 - val_argmax_mean_iou_1: 0.9188\n",
      "Epoch 26/35\n",
      "558/558 [==============================] - 958s 2s/step - loss: 0.0785 - accuracy: 0.9759 - argmax_mean_iou_1: 0.9492 - val_loss: 0.1207 - val_accuracy: 0.9626 - val_argmax_mean_iou_1: 0.9191\n",
      "Epoch 27/35\n",
      "558/558 [==============================] - 975s 2s/step - loss: 0.0788 - accuracy: 0.9757 - argmax_mean_iou_1: 0.9489 - val_loss: 0.1162 - val_accuracy: 0.9626 - val_argmax_mean_iou_1: 0.9189\n",
      "Epoch 28/35\n",
      "558/558 [==============================] - 1013s 2s/step - loss: 0.0791 - accuracy: 0.9757 - argmax_mean_iou_1: 0.9488 - val_loss: 0.1200 - val_accuracy: 0.9622 - val_argmax_mean_iou_1: 0.9180\n",
      "Epoch 29/35\n",
      "558/558 [==============================] - 1037s 2s/step - loss: 0.0791 - accuracy: 0.9756 - argmax_mean_iou_1: 0.9487 - val_loss: 0.1161 - val_accuracy: 0.9630 - val_argmax_mean_iou_1: 0.9197\n",
      "Epoch 30/35\n",
      "558/558 [==============================] - 1187s 2s/step - loss: 0.0798 - accuracy: 0.9754 - argmax_mean_iou_1: 0.9481 - val_loss: 0.1141 - val_accuracy: 0.9628 - val_argmax_mean_iou_1: 0.9194\n",
      "Epoch 31/35\n",
      "558/558 [==============================] - 1201s 2s/step - loss: 0.0798 - accuracy: 0.9753 - argmax_mean_iou_1: 0.9482 - val_loss: 0.1174 - val_accuracy: 0.9627 - val_argmax_mean_iou_1: 0.9192\n",
      "Epoch 32/35\n",
      "558/558 [==============================] - 1019s 2s/step - loss: 0.0794 - accuracy: 0.9755 - argmax_mean_iou_1: 0.9486 - val_loss: 0.1149 - val_accuracy: 0.9632 - val_argmax_mean_iou_1: 0.9201\n",
      "Epoch 33/35\n",
      "558/558 [==============================] - 931s 2s/step - loss: 0.0801 - accuracy: 0.9753 - argmax_mean_iou_1: 0.9480 - val_loss: 0.1198 - val_accuracy: 0.9623 - val_argmax_mean_iou_1: 0.9183\n",
      "Epoch 34/35\n",
      "558/558 [==============================] - 924s 2s/step - loss: 0.0798 - accuracy: 0.9754 - argmax_mean_iou_1: 0.9484 - val_loss: 0.1208 - val_accuracy: 0.9611 - val_argmax_mean_iou_1: 0.9157\n",
      "Epoch 35/35\n",
      "558/558 [==============================] - 924s 2s/step - loss: 0.0795 - accuracy: 0.9756 - argmax_mean_iou_1: 0.9487 - val_loss: 0.1219 - val_accuracy: 0.9616 - val_argmax_mean_iou_1: 0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses while saving (showing 5 of 210). These functions will not be directly callable after loading.\n",
      "C:\\Users\\andre\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/EE/project/FPGA/benchmark_model/pruned_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/EE/project/FPGA/benchmark_model/pruned_model.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "logdir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]   \n",
    "history = pruned_model.fit(fit_ds,\n",
    "                validation_data=valid_ds,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks) \n",
    "pruned_model.save('E:/EE/project/FPGA/benchmark_model/pruned_model.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164450c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "stripped_pruned_model.save(\"E:/EE/project/FPGA/benchmark_model/stripped_pruned_model.h5\",save_format='h5')\n",
    "stripped_pruned_model_copy = tf.keras.models.clone_model(stripped_pruned_model)\n",
    "stripped_pruned_model_copy.set_weights(stripped_pruned_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61446258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sparsity preserving clustering model:\n",
      "Epoch 1/10\n",
      "558/558 [==============================] - 882s 2s/step - loss: 0.3296 - accuracy: 0.8760 - argmax_mean_iou_2: 0.7613 - val_loss: 0.2390 - val_accuracy: 0.9304 - val_argmax_mean_iou_2: 0.8547\n",
      "Epoch 2/10\n",
      "558/558 [==============================] - 869s 2s/step - loss: 0.2361 - accuracy: 0.9406 - argmax_mean_iou_2: 0.8799 - val_loss: 0.2294 - val_accuracy: 0.9357 - val_argmax_mean_iou_2: 0.8646\n",
      "Epoch 3/10\n",
      "558/558 [==============================] - 865s 2s/step - loss: 0.2296 - accuracy: 0.9456 - argmax_mean_iou_2: 0.8898 - val_loss: 0.2237 - val_accuracy: 0.9394 - val_argmax_mean_iou_2: 0.8716\n",
      "Epoch 4/10\n",
      "558/558 [==============================] - 887s 2s/step - loss: 0.2223 - accuracy: 0.9486 - argmax_mean_iou_2: 0.8952 - val_loss: 0.2195 - val_accuracy: 0.9420 - val_argmax_mean_iou_2: 0.8771\n",
      "Epoch 5/10\n",
      "558/558 [==============================] - 877s 2s/step - loss: 0.2216 - accuracy: 0.9494 - argmax_mean_iou_2: 0.8969 - val_loss: 0.2165 - val_accuracy: 0.9416 - val_argmax_mean_iou_2: 0.8765\n",
      "Epoch 6/10\n",
      "558/558 [==============================] - 897s 2s/step - loss: 0.2180 - accuracy: 0.9512 - argmax_mean_iou_2: 0.9001 - val_loss: 0.2220 - val_accuracy: 0.9398 - val_argmax_mean_iou_2: 0.8722\n",
      "Epoch 7/10\n",
      "558/558 [==============================] - 893s 2s/step - loss: 0.2165 - accuracy: 0.9516 - argmax_mean_iou_2: 0.9010 - val_loss: 0.2144 - val_accuracy: 0.9428 - val_argmax_mean_iou_2: 0.8790\n",
      "Epoch 8/10\n",
      "558/558 [==============================] - 889s 2s/step - loss: 0.1898 - accuracy: 0.9463 - argmax_mean_iou_2: 0.8910 - val_loss: 0.1969 - val_accuracy: 0.9265 - val_argmax_mean_iou_2: 0.8500\n",
      "Epoch 9/10\n",
      "558/558 [==============================] - 863s 2s/step - loss: 0.1660 - accuracy: 0.9405 - argmax_mean_iou_2: 0.8796 - val_loss: 0.1975 - val_accuracy: 0.9294 - val_argmax_mean_iou_2: 0.8542\n",
      "Epoch 10/10\n",
      "558/558 [==============================] - 874s 2s/step - loss: 0.1505 - accuracy: 0.9463 - argmax_mean_iou_2: 0.8909 - val_loss: 0.1911 - val_accuracy: 0.9346 - val_argmax_mean_iou_2: 0.8631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv2d_1_layer_call_and_return_conditional_losses while saving (showing 5 of 210). These functions will not be directly callable after loading.\n",
      "C:\\Users\\andre\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/EE/project/FPGA/benchmark_model/clustered_model.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/EE/project/FPGA/benchmark_model/clustered_model.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Clustering\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "from tensorflow_model_optimization.python.core.clustering.keras.experimental import (\n",
    "    cluster,\n",
    ")\n",
    "\n",
    "cluster_weights = cluster.cluster_weights\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 8,\n",
    "  'cluster_centroids_init': CentroidInitialization.DENSITY_BASED,\n",
    "  'preserve_sparsity': True\n",
    "}\n",
    "\n",
    "sparsity_clustered_model = cluster_weights(stripped_pruned_model_copy, **clustering_params)\n",
    "\n",
    "sparsity_clustered_model.compile(opt, loss=cce,\n",
    "                  metrics=['accuracy', ArgmaxMeanIOU(NUM_CLASSES)])\n",
    "\n",
    "print('Train sparsity preserving clustering model:')\n",
    "sparsity_clustered_model.fit(fit_ds, validation_data=valid_ds, epochs=10)\n",
    "sparsity_clustered_model.save(\"E:/EE/project/FPGA/benchmark_model/clustered_model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943123cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_sparsity_clustered_model = tfmot.clustering.keras.strip_clustering(sparsity_clustered_model)\n",
    "stripped_sparsity_clustered_model.save(\"E:/EE/project/FPGA/benchmark_model/stripped_clustered_model.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8191ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
