{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f41d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import numpy as np\n",
    "class ArgmaxMeanIOU(metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)\n",
    "\n",
    "def img_pred(src,model,image_size):\n",
    "    src = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    #cv2_imshow(src)\n",
    "    image = cv2.resize(src,image_size,interpolation=cv2.INTER_CUBIC)\n",
    "    #cv2_imshow(src)\n",
    "    image = image/255\n",
    "    image =  tf.image.per_image_standardization(image)\n",
    "    data = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    data = tf.expand_dims(data, axis=0)\n",
    "    s = time.time()\n",
    "    pred = model.predict(data)\n",
    "    e = time.time()\n",
    "    fps = 1/(e-s)\n",
    "    seg = tf.argmax(pred[0], axis=-1)\n",
    "    seg = seg[..., tf.newaxis]\n",
    "    seg = tf.keras.preprocessing.image.array_to_img(seg)\n",
    "    #plt.imshow(seg)\n",
    "    seg = cv2.cvtColor(np.array(seg), cv2.COLOR_BGR2RGB)\n",
    "    seg = cv2.resize(seg,(src.shape[1],src.shape[0]),interpolation=cv2.INTER_CUBIC)\n",
    "    result = cv2.addWeighted(np.array(src), 0.6, seg, 0.5, 0, dtype = cv2.CV_8U)\n",
    "    return src, seg, result, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c331c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "from tqdm import notebook\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "def gen_seg_vid(cap,out,model,subtitle):\n",
    "    length = 1000\n",
    "    progress = notebook.tqdm(total = length)\n",
    "    AVG_FPS = 0\n",
    "  #while(cap.isOpened()):\n",
    "    for _ in range(length):\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)\n",
    "        channels = cv2.split(frame)\n",
    "        frame = cv2.merge(channels)\n",
    "        channels[0]\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR)\n",
    "        cv2.imshow('frame',cv2.resize(frame,(800,400),interpolation=cv2.INTER_CUBIC))\n",
    "        cv2.waitKey(200)\n",
    "        if ret == True:\n",
    "            total_fps = []\n",
    "            m = model\n",
    "            shape = (256,128)\n",
    "            result = img_pred(frame,m,shape)\n",
    "            img_seg = result[2]\n",
    "            fps = result[3]\n",
    "            total_fps.append(fps)\n",
    "            if (_ % 5) == 0:\n",
    "                AVG_FPS = stat.mean(total_fps)\n",
    "            x = 'AVG_FPS:'\n",
    "            y = 'FPS: '\n",
    "            img_seg = cv2.resize(img_seg,(512,256),interpolation=cv2.INTER_CUBIC)\n",
    "            text = \"{}{:.3f}\".format(x,AVG_FPS)\n",
    "            text1 = \"{}{:.3f}\".format(y,fps)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            img_out = cv2.cvtColor(img_seg, cv2.COLOR_BGR2RGB)\n",
    "            cv2.putText(img_out, text , (350,230), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img_out, text1 , (350,210), font, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(img_out, subtitle , (140,20), font, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            img_out = cv2.resize(img_out,(1800,1300),interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "            out.write(img_out)\n",
    "            progress.update(1)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return AVG_FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8771909f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986153405f774ff8bffe06cf0f58bbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc true_divide",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-041640f17671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msubtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Benchmark mIoU(92%)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgen_seg_vid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-ed6abb1b3573>\u001b[0m in \u001b[0;36mgen_seg_vid\u001b[1;34m(cap, out, model, subtitle)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mchannels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_YUV2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc true_divide"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('E:/EE/project/FPGA/benchmark_model/model_benchmark.tf',custom_objects={'ArgmaxMeanIOU': ArgmaxMeanIOU}, compile=False)\n",
    "cap = cv2.VideoCapture('E:\\EE\\project\\FPGA\\Driving_data.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('E:/EE/project/FPGA/benchmark_model/City_GPU_Ynorm.mp4',fourcc,20,(1800,1300))\n",
    "\n",
    "subtitle = 'Benchmark mIoU(92%)'\n",
    "\n",
    "gen_seg_vid(cap,out,model,subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ff16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread('E:/EE/project/FPGA/test_02.png')\n",
    "start = time.time()\n",
    "result = img_pred(src,model,(256,128))[2]\n",
    "end = time.time()\n",
    "fps = 1/(end-start)\n",
    "print('fps =',fps)\n",
    "result = cv2.resize(result,(1024,512),interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"result\",result)\n",
    "cv2.waitKey (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f38d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shadow_removal(frame):\n",
    "    subtraction = cv2.\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
